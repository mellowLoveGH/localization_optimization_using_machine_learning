{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPS_indoor_outdoor_04.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT5DxW5eky-q",
        "outputId": "083cb238-cc9b-45cb-cdfc-3dea9810ff5a"
      },
      "source": [
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1NkpINck9BO",
        "outputId": "4063bf8a-22f3-4771-dc3e-43e071d17a21"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 12 features + 1 class\n",
        "cols = ['number','snrtotal','snrave','numtotal','elesnrtotal','elesnrave','snr20num','snr15num','gpsz_tmean','gpsz_stdz','tenTotal','R','Class']\n",
        "cols = ['snrtotal','snrave','elesnrtotal','elesnrave','gpsz_tmean','gpsz_stdz','tenTotal','R','Class']\n",
        "cols_update = ['snrave','numtotal','elesnrtotal','elesnrave','snr15num','gpsz_tmean', 'tenTotal','R','Class']\n",
        "cols_update = ['number','snrtotal','snrave','numtotal','elesnrtotal','elesnrave','snr20num','snr15num','gpsz_tmean','tenTotal','R','Class']\n",
        "cols_update = cols\n",
        "\n",
        "# collected data\n",
        "dataxy_sub01 = pd.read_csv(\"./test01.csv\") # \"地铁室外跑\"\n",
        "dataxy_sub02 = pd.read_csv(\"./test02.csv\") # 地铁站大棚\n",
        "dataxy_sub03 = pd.read_csv(\"./test03.csv\") # 楼梯电梯地下地铁站口\n",
        "dataxy_sub04 = pd.read_csv(\"./test04.csv\") # 地铁场景的数据\n",
        "dataxy_sub05 = pd.read_csv(\"./test05.csv\") # \"主流场景\"\n",
        "print(dataxy_sub01.shape, dataxy_sub02.shape, dataxy_sub03.shape, dataxy_sub04.shape, dataxy_sub05.shape)\n",
        "\n",
        "dataxy_sub00 = pd.concat([dataxy_sub02, dataxy_sub03, dataxy_sub04, dataxy_sub05])\n",
        "print(dataxy_sub00.shape)\n",
        "\n",
        "# log data\n",
        "log_dataxy01 = pd.read_csv(\"./log_data01.csv\") \n",
        "log_dataxy02 = pd.read_csv(\"./log_data02.csv\") \n",
        "log_dataxy03 = pd.read_csv(\"./log_data03.csv\") \n",
        "log_dataxy04 = pd.read_csv(\"./log_data04.csv\") \n",
        "print(log_dataxy01.shape, log_dataxy02.shape, log_dataxy03.shape, log_dataxy04.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(963, 13) (1115, 13) (1578, 13) (4982, 13) (21208, 13)\n",
            "(28883, 13)\n",
            "(19237, 13) (12586, 13) (26422, 13) (21264, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV68v4s7lQq6"
      },
      "source": [
        "#\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "def shuffle_split(df_tmp, cols, ratio=0.25):\n",
        "  df_shuffled = df_tmp.copy()\n",
        "  df_shuffled = shuffle(df_shuffled, random_state=0)\n",
        "  # set \"indoor\" as 1, \"outdoor\" as 0\n",
        "  df_shuffled[\"Class\"] = df_shuffled[\"Class\"].apply(lambda x: 1 if x==\"indoor\" else 0)\n",
        "  # split as \"training\" & \"testing\"\n",
        "  L = len(df_tmp)\n",
        "  n1 = int(L*ratio)\n",
        "  train_xy = df_shuffled[:n1]\n",
        "  test_xy = df_shuffled[n1:]\n",
        "  # features + class/label\n",
        "  X_train = train_xy[cols[:-1]]\n",
        "  y_train = train_xy[cols[-1]]\n",
        "  X_test = test_xy[cols[:-1]]\n",
        "  y_test = test_xy[cols[-1]]\n",
        "  return X_train, y_train, X_test, y_test\n",
        "\n",
        "def just_split(df_tmp, cols):\n",
        "  df_shuffled = shuffle(df_tmp, random_state=0)\n",
        "  df_shuffled[\"Class\"] = df_shuffled[\"Class\"].apply(lambda x: 1 if x==\"indoor\" else 0)\n",
        "  X = df_shuffled[cols[:-1]]\n",
        "  y = df_shuffled[cols[-1]]\n",
        "  return X, y\n",
        "\n",
        "def log_evaluation(y_test, y_pred, verbose=True):\n",
        "  yt = {0:0, 1:0}\n",
        "  yp = {0:0, 1:0}\n",
        "  iv = 0\n",
        "  ov = 0\n",
        "  #\n",
        "  i = 0\n",
        "  L = len(y_test)\n",
        "  while i<L:\n",
        "    vt = y_test[i]\n",
        "    vp = y_pred[i]\n",
        "    #\n",
        "    if vt == 0:\n",
        "      yt[0] = yt[0] + 1\n",
        "    else:\n",
        "      yt[1] = yt[1] + 1\n",
        "    if vp == 0:\n",
        "      yp[0] = yp[0] + 1\n",
        "    else:\n",
        "      yp[1] = yp[1] + 1\n",
        "    #\n",
        "    if vt==vp:\n",
        "      if vt==0:\n",
        "        ov = ov + 1\n",
        "      else:\n",
        "        iv = iv + 1\n",
        "    #\n",
        "    i = i + 1\n",
        "  #\n",
        "  yt0 = round(yt[0]/L, 3)\n",
        "  yt1 = round(yt[1]/L, 3)\n",
        "  yp0 = round(yp[0]/L, 3)\n",
        "  yp1 = round(yp[1]/L, 3)\n",
        "  if verbose:\n",
        "    print(\"prediction by: \\t\\t wifi\\t\\t model:\")\n",
        "    print(\"outdoor - 0: \\t\\t\", yt0, yt[0], \"\\t\", yp0, yp[0])\n",
        "    print(\"indoor - 1: \\t\\t\", yt1, yt[1], \"\\t\", yp1, yp[1])\n",
        "    print(\"comparison between wifi & model: \")\n",
        "    print(\"outdoor overlapping - 0: \\t\", round(ov/L, 3), ov)\n",
        "    print(\"indoor overlapping - 1: \\t\", round(iv/L, 3), iv)\n",
        "  return yt, yp, iv, ov, L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD2diXuXM7hx",
        "outputId": "5099fd9f-7561-485d-ca28-525d01264063"
      },
      "source": [
        "# NN\n",
        "X_train, y_train, X_test, y_test = shuffle_split(dataxy_sub00, cols, ratio=0.7)\n",
        "X_log, y_log = just_split(log_dataxy01, cols)\n",
        "y_log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15458    0\n",
              "15175    0\n",
              "9132     0\n",
              "10435    0\n",
              "3249     0\n",
              "        ..\n",
              "9225     0\n",
              "13123    0\n",
              "9845     0\n",
              "10799    0\n",
              "2732     0\n",
              "Name: Class, Length: 19237, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RlooKpRlX2Z",
        "outputId": "c65afaca-d305-4ae5-a915-99aa20dfa353"
      },
      "source": [
        "# NN\n",
        "X_train, y_train, X_test, y_test = shuffle_split(dataxy_sub00, cols, ratio=0.7)\n",
        "X_log, y_log = just_split(log_dataxy01, cols)\n",
        "\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "\"\"\"from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)\"\"\"\n",
        "\n",
        "def NN_model(X_train, y_train, X_test, y_test, X_log, y_log, count, n1=10, n2=6, n3=3):\n",
        "  n_features = 8 # 12\n",
        "  model = Sequential()\n",
        "  model.add(Dense(n1, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "  model.add(Dense(n2, activation='relu'))\n",
        "  model.add(Dense(n3, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  # compile the model\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  # fit the model\n",
        "  model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "  loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "  print(\"loss: \", loss, \"\\t accuracy for testing: \", acc)\n",
        "  #\n",
        "  for ratio in range(3, 8):\n",
        "    y_pred = (model.predict(X_log) > ratio/10).astype(\"int32\")\n",
        "    y_pred = y_pred.reshape(len(y_pred),)\n",
        "    yt, yp, iv, ov, L = log_evaluation(y_log, y_pred, False)\n",
        "    #\n",
        "    print(\"--------------------------------------- \", iv/yt[1], ov/yt[0], \"\\t\", n1, n2, n3, ratio)\n",
        "    if iv/yt[1] > 0.6 and ov/yt[0] > 0.7:\n",
        "      model.save(\"my_model_0825_new_\"+str(count)+\".h5\")\n",
        "  return yt, yp, iv, ov, L\n",
        "\n",
        "search_flag = False\n",
        "search_flag = True\n",
        "count = 0\n",
        "if search_flag:\n",
        "  for n1 in range(10, 11):\n",
        "    for n2 in range(6, 10):\n",
        "      for n3 in range(3, 10):\n",
        "        tmp = NN_model(X_train, y_train, X_test, y_test, X_log, y_log, count, n1, n2, n3)\n",
        "        count = count + 1\n",
        "# 10, 3, 4-9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.6.0\n",
            "loss:  0.20440861582756042 \t accuracy for testing:  0.9227928519248962\n",
            "---------------------------------------  0.32792207792207795 0.6784173903042153 \t 10 6 3 3\n",
            "---------------------------------------  0.25703463203463206 0.7398355282074875 \t 10 6 3 4\n",
            "---------------------------------------  0.23593073593073594 0.7705445971591236 \t 10 6 3 5\n",
            "---------------------------------------  0.21103896103896103 0.7910748174133073 \t 10 6 3 6\n",
            "---------------------------------------  0.1937229437229437 0.8094197481166254 \t 10 6 3 7\n",
            "loss:  0.2960417568683624 \t accuracy for testing:  0.8724755048751831\n",
            "---------------------------------------  0.12012987012987013 0.8715854850767727 \t 10 6 4 3\n",
            "---------------------------------------  0.11038961038961038 0.8817643337742251 \t 10 6 4 4\n",
            "---------------------------------------  0.10227272727272728 0.8906205072172063 \t 10 6 4 5\n",
            "---------------------------------------  0.09686147186147186 0.898499051124274 \t 10 6 4 6\n",
            "---------------------------------------  0.09253246753246754 0.9065501178906205 \t 10 6 4 7\n",
            "loss:  0.695042610168457 \t accuracy for testing:  0.8814772367477417\n",
            "---------------------------------------  0.1634199134199134 0.8338604865144632 \t 10 6 5 3\n",
            "---------------------------------------  0.15746753246753248 0.8403013399275404 \t 10 6 5 4\n",
            "---------------------------------------  0.14989177489177488 0.8457070561849445 \t 10 6 5 5\n",
            "---------------------------------------  0.14502164502164502 0.851055264822589 \t 10 6 5 6\n",
            "---------------------------------------  0.1396103896103896 0.856633503939272 \t 10 6 5 7\n",
            "loss:  0.21886798739433289 \t accuracy for testing:  0.9165608882904053\n",
            "---------------------------------------  0.25865800865800864 0.7452987520846512 \t 10 6 6 3\n",
            "---------------------------------------  0.22456709956709955 0.7728449019495083 \t 10 6 6 4\n",
            "---------------------------------------  0.2012987012987013 0.7959629650928748 \t 10 6 6 5\n",
            "---------------------------------------  0.17965367965367965 0.8166082005865777 \t 10 6 6 6\n",
            "---------------------------------------  0.1553030303030303 0.835700730346771 \t 10 6 6 7\n",
            "loss:  0.30267155170440674 \t accuracy for testing:  0.9069821238517761\n",
            "---------------------------------------  0.1975108225108225 0.796538041290471 \t 10 6 7 3\n",
            "---------------------------------------  0.18885281385281386 0.8106274081315774 \t 10 6 7 4\n",
            "---------------------------------------  0.17424242424242425 0.8205187187302317 \t 10 6 7 5\n",
            "---------------------------------------  0.16287878787878787 0.8306400598079245 \t 10 6 7 6\n",
            "---------------------------------------  0.15043290043290045 0.8426016447179251 \t 10 6 7 7\n",
            "loss:  0.6762924790382385 \t accuracy for testing:  0.8933641314506531\n",
            "---------------------------------------  0.17965367965367965 0.8165506929668181 \t 10 6 8 3\n",
            "---------------------------------------  0.1737012987012987 0.8216688711254241 \t 10 6 8 4\n",
            "---------------------------------------  0.1699134199134199 0.8271320950025879 \t 10 6 8 5\n",
            "---------------------------------------  0.16558441558441558 0.8324227960204728 \t 10 6 8 6\n",
            "---------------------------------------  0.16125541125541126 0.8383460808557134 \t 10 6 8 7\n",
            "loss:  0.205657497048378 \t accuracy for testing:  0.9193306565284729\n",
            "---------------------------------------  0.32196969696969696 0.66415550060383 \t 10 6 9 3\n",
            "---------------------------------------  0.22564935064935066 0.7681292771292196 \t 10 6 9 4\n",
            "---------------------------------------  0.18019480519480519 0.8116050376674909 \t 10 6 9 5\n",
            "---------------------------------------  0.15692640692640691 0.8349531312898959 \t 10 6 9 6\n",
            "---------------------------------------  0.14123376623376624 0.8539306458105699 \t 10 6 9 7\n",
            "loss:  0.2088584303855896 \t accuracy for testing:  0.92152339220047\n",
            "---------------------------------------  0.20183982683982685 0.8003910518143654 \t 10 7 3 3\n",
            "---------------------------------------  0.18668831168831168 0.8136178043590776 \t 10 7 3 4\n",
            "---------------------------------------  0.1737012987012987 0.8248892978319627 \t 10 7 3 5\n",
            "---------------------------------------  0.16233766233766234 0.8362758065443672 \t 10 7 3 6\n",
            "---------------------------------------  0.15205627705627706 0.8478348381160504 \t 10 7 3 7\n",
            "loss:  0.2294670045375824 \t accuracy for testing:  0.9177149534225464\n",
            "---------------------------------------  0.43885281385281383 0.5629995974466617 \t 10 7 4 3\n",
            "---------------------------------------  0.29653679653679654 0.7069411697049859 \t 10 7 4 4\n",
            "---------------------------------------  0.204004329004329 0.7940077060210478 \t 10 7 4 5\n",
            "---------------------------------------  0.1525974025974026 0.84185404566105 \t 10 7 4 6\n",
            "---------------------------------------  0.1277056277056277 0.8665823221576859 \t 10 7 4 7\n",
            "loss:  0.2156057059764862 \t accuracy for testing:  0.9147143959999084\n",
            "---------------------------------------  0.8051948051948052 0.1891425613893841 \t 10 7 5 3\n",
            "---------------------------------------  0.7754329004329005 0.220484214158376 \t 10 7 5 4\n",
            "---------------------------------------  0.7521645021645021 0.247742825924435 \t 10 7 5 5\n",
            "---------------------------------------  0.7207792207792207 0.2794295244119846 \t 10 7 5 6\n",
            "---------------------------------------  0.6834415584415584 0.3100235781241014 \t 10 7 5 7\n",
            "loss:  0.20938679575920105 \t accuracy for testing:  0.9171379208564758\n",
            "---------------------------------------  0.4096320346320346 0.5997469664730577 \t 10 7 6 3\n",
            "---------------------------------------  0.39556277056277056 0.6155615619069527 \t 10 7 6 4\n",
            "---------------------------------------  0.3847402597402597 0.6280407153947898 \t 10 7 6 5\n",
            "---------------------------------------  0.37283549783549785 0.6394272241071942 \t 10 7 6 6\n",
            "---------------------------------------  0.36093073593073594 0.6513313013974351 \t 10 7 6 7\n",
            "loss:  0.22255170345306396 \t accuracy for testing:  0.9095210433006287\n",
            "---------------------------------------  0.29707792207792205 0.7018804991661395 \t 10 7 7 3\n",
            "---------------------------------------  0.23863636363636365 0.7599631951233539 \t 10 7 7 4\n",
            "---------------------------------------  0.20346320346320346 0.7962505031916729 \t 10 7 7 5\n",
            "---------------------------------------  0.18344155844155843 0.8208637644487895 \t 10 7 7 6\n",
            "---------------------------------------  0.1590909090909091 0.8385186037149922 \t 10 7 7 7\n",
            "loss:  0.19662494957447052 \t accuracy for testing:  0.9248701930046082\n",
            "---------------------------------------  0.31385281385281383 0.6683535568462822 \t 10 7 8 3\n",
            "---------------------------------------  0.24134199134199133 0.7420783253781126 \t 10 7 8 4\n",
            "---------------------------------------  0.2012987012987013 0.7923399850480188 \t 10 7 8 5\n",
            "---------------------------------------  0.16612554112554112 0.8315601817240784 \t 10 7 8 6\n",
            "---------------------------------------  0.1461038961038961 0.8541031686698487 \t 10 7 8 7\n",
            "loss:  0.22687289118766785 \t accuracy for testing:  0.9124062061309814\n",
            "---------------------------------------  0.29653679653679654 0.7045258496750819 \t 10 7 9 3\n",
            "---------------------------------------  0.26406926406926406 0.7327045833572948 \t 10 7 9 4\n",
            "---------------------------------------  0.24025974025974026 0.7557651388809017 \t 10 7 9 5\n",
            "---------------------------------------  0.22023809523809523 0.7762953591350854 \t 10 7 9 6\n",
            "---------------------------------------  0.19318181818181818 0.798493300362298 \t 10 7 9 7\n",
            "loss:  0.22947534918785095 \t accuracy for testing:  0.9117137789726257\n",
            "---------------------------------------  0.23755411255411255 0.7678992466501812 \t 10 8 3 3\n",
            "---------------------------------------  0.22077922077922077 0.7823336592098453 \t 10 8 3 4\n",
            "---------------------------------------  0.20941558441558442 0.7951003507964806 \t 10 8 3 5\n",
            "---------------------------------------  0.19913419913419914 0.8066018747484042 \t 10 8 3 6\n",
            "---------------------------------------  0.1856060606060606 0.8180458910805681 \t 10 8 3 7\n",
            "loss:  0.2319922149181366 \t accuracy for testing:  0.9100980758666992\n",
            "---------------------------------------  0.16558441558441558 0.8385761113347519 \t 10 8 4 3\n",
            "---------------------------------------  0.15097402597402598 0.8492150209902812 \t 10 8 4 4\n",
            "---------------------------------------  0.14123376623376624 0.8581862096727817 \t 10 8 4 5\n",
            "---------------------------------------  0.12932900432900432 0.8668123526367244 \t 10 8 4 6\n",
            "---------------------------------------  0.1185064935064935 0.8757260336994652 \t 10 8 4 7\n",
            "loss:  0.2407478243112564 \t accuracy for testing:  0.9102135300636292\n",
            "---------------------------------------  0.2656926406926407 0.7331071366956121 \t 10 8 5 3\n",
            "---------------------------------------  0.24783549783549783 0.7508769912013342 \t 10 8 5 4\n",
            "---------------------------------------  0.2343073593073593 0.7669216171142677 \t 10 8 5 5\n",
            "---------------------------------------  0.2196969696969697 0.7809534763356145 \t 10 8 5 6\n",
            "---------------------------------------  0.20346320346320346 0.7962505031916729 \t 10 8 5 7\n",
            "loss:  0.3243924379348755 \t accuracy for testing:  0.8917484283447266\n",
            "---------------------------------------  0.20725108225108224 0.7894070964402783 \t 10 8 6 3\n",
            "---------------------------------------  0.19155844155844157 0.8053942147334522 \t 10 8 6 4\n",
            "---------------------------------------  0.1764069264069264 0.8190235206164816 \t 10 8 6 5\n",
            "---------------------------------------  0.16233766233766234 0.8317902122031169 \t 10 8 6 6\n",
            "---------------------------------------  0.15476190476190477 0.8438668123526367 \t 10 8 6 7\n",
            "loss:  0.2297675609588623 \t accuracy for testing:  0.9111367464065552\n",
            "---------------------------------------  0.17316017316017315 0.8275346483409052 \t 10 8 7 3\n",
            "---------------------------------------  0.16017316017316016 0.8390936799125884 \t 10 8 7 4\n",
            "---------------------------------------  0.15151515151515152 0.8484099143136465 \t 10 8 7 5\n",
            "---------------------------------------  0.14285714285714285 0.8566910115590316 \t 10 8 7 6\n",
            "---------------------------------------  0.1314935064935065 0.865662200241532 \t 10 8 7 7\n",
            "loss:  0.7080734968185425 \t accuracy for testing:  0.8845931887626648\n",
            "---------------------------------------  0.15692640692640691 0.8373109437000402 \t 10 8 8 3\n",
            "---------------------------------------  0.15151515151515152 0.8436942894933579 \t 10 8 8 4\n",
            "---------------------------------------  0.1471861471861472 0.8485249295531658 \t 10 8 8 5\n",
            "---------------------------------------  0.14393939393939395 0.8538731381908102 \t 10 8 8 6\n",
            "---------------------------------------  0.14015151515151514 0.8609465754212433 \t 10 8 8 7\n",
            "loss:  0.2309093028306961 \t accuracy for testing:  0.904558539390564\n",
            "---------------------------------------  0.31764069264069267 0.6806026798550808 \t 10 8 9 3\n",
            "---------------------------------------  0.27976190476190477 0.7229282879981598 \t 10 8 9 4\n",
            "---------------------------------------  0.24891774891774893 0.7556501236413825 \t 10 8 9 5\n",
            "---------------------------------------  0.2159090909090909 0.7845764563804705 \t 10 8 9 6\n",
            "---------------------------------------  0.1812770562770563 0.8132727586405198 \t 10 8 9 7\n",
            "loss:  0.22489242255687714 \t accuracy for testing:  0.914021909236908\n",
            "---------------------------------------  0.18344155844155843 0.8141353729369142 \t 10 9 3 3\n",
            "---------------------------------------  0.17153679653679654 0.827707171200184 \t 10 9 3 4\n",
            "---------------------------------------  0.16017316017316016 0.8373109437000402 \t 10 9 3 5\n",
            "---------------------------------------  0.1525974025974026 0.8482373914543677 \t 10 9 3 6\n",
            "---------------------------------------  0.14393939393939395 0.858128702053022 \t 10 9 3 7\n",
            "loss:  0.22894975543022156 \t accuracy for testing:  0.9100980758666992\n",
            "---------------------------------------  0.15746753246753248 0.843234228535281 \t 10 9 4 3\n",
            "---------------------------------------  0.1396103896103896 0.8603714992236471 \t 10 9 4 4\n",
            "---------------------------------------  0.12554112554112554 0.8712404393582149 \t 10 9 4 5\n",
            "---------------------------------------  0.1185064935064935 0.8772212318132152 \t 10 9 4 6\n",
            "---------------------------------------  0.11147186147186147 0.8846972223819656 \t 10 9 4 7\n",
            "loss:  0.33995744585990906 \t accuracy for testing:  0.8832083344459534\n",
            "---------------------------------------  0.31547619047619047 0.6924492495255621 \t 10 9 5 3\n",
            "---------------------------------------  0.29545454545454547 0.7069986773247455 \t 10 9 5 4\n",
            "---------------------------------------  0.2824675324675325 0.7205704755880155 \t 10 9 5 5\n",
            "---------------------------------------  0.2683982683982684 0.7327620909770545 \t 10 9 5 6\n",
            "---------------------------------------  0.25757575757575757 0.7450687216056128 \t 10 9 5 7\n",
            "loss:  0.2351943403482437 \t accuracy for testing:  0.9104443192481995\n",
            "---------------------------------------  0.15584415584415584 0.8440968428316752 \t 10 9 6 3\n",
            "---------------------------------------  0.14556277056277056 0.8547932601069642 \t 10 9 6 4\n",
            "---------------------------------------  0.13582251082251082 0.8638794640289839 \t 10 9 6 5\n",
            "---------------------------------------  0.12391774891774891 0.8729081603312439 \t 10 9 6 6\n",
            "---------------------------------------  0.1130952380952381 0.8809017194778308 \t 10 9 6 7\n",
            "loss:  0.24673868715763092 \t accuracy for testing:  0.8962492942810059\n",
            "---------------------------------------  0.42478354978354976 0.5804819138535856 \t 10 9 7 3\n",
            "---------------------------------------  0.33225108225108224 0.667778480648686 \t 10 9 7 4\n",
            "---------------------------------------  0.26461038961038963 0.7316694462016217 \t 10 9 7 5\n",
            "---------------------------------------  0.2132034632034632 0.7842314106619127 \t 10 9 7 6\n",
            "---------------------------------------  0.16504329004329005 0.8299499683708091 \t 10 9 7 7\n",
            "loss:  0.23579975962638855 \t accuracy for testing:  0.9132140874862671\n",
            "---------------------------------------  0.23755411255411255 0.763701190407729 \t 10 9 8 3\n",
            "---------------------------------------  0.20346320346320346 0.7944677669791247 \t 10 9 8 4\n",
            "---------------------------------------  0.1774891774891775 0.8187934901374432 \t 10 9 8 5\n",
            "---------------------------------------  0.15800865800865802 0.8400138018287423 \t 10 9 8 6\n",
            "---------------------------------------  0.13852813852813853 0.8600264535050894 \t 10 9 8 7\n",
            "loss:  0.30255481600761414 \t accuracy for testing:  0.8742066025733948\n",
            "---------------------------------------  0.20292207792207792 0.7931450917246535 \t 10 9 9 3\n",
            "---------------------------------------  0.1747835497835498 0.8194835815745586 \t 10 9 9 4\n",
            "---------------------------------------  0.1525974025974026 0.839611248490425 \t 10 9 9 5\n",
            "---------------------------------------  0.13365800865800867 0.8560584277416757 \t 10 9 9 6\n",
            "---------------------------------------  0.12121212121212122 0.8729081603312439 \t 10 9 9 7\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}